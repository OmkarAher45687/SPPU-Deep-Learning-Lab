{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8bb515-b733-4bd9-9e34-74496f016896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "\n",
    "# x = np.random.rand(100).astype(np.float32)\n",
    "# y = 0.2 * x + 0.2\n",
    "# W = tf.Variable(np.random.normal([1]))\n",
    "# b = tf.Variable(np.zeros([1]))\n",
    "\n",
    "# def mse_loss():\n",
    "#     y_pred = W * x + b\n",
    "#     loss = tf.reduce_mean(tf.square(y_pred - y))\n",
    "#     return loss\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# for step in range(5000):\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         current_loss = mse_loss()\n",
    "#     gradients = tape.gradient(current_loss, [W, b])\n",
    "#     optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "#     if step % 500 == 0:\n",
    "#         print(f\"Step {step}: W={W.numpy()}, b={b.numpy()}, Loss={current_loss.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60354c08-24d3-4935-ac33-d90ca9236ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Create random input data (x) with 100 values and convert to a 32-bit float type\n",
    "x = np.random.rand(100).astype(np.float32)\n",
    "\n",
    "# Define the target output (y) using a linear function with a known relationship to x\n",
    "# The equation here is y = 0.2 * x + 0.2\n",
    "y = 0.2 * x + 0.2\n",
    "\n",
    "# Initialize the weight (W) as a TensorFlow variable with a random normal distribution.\n",
    "# This represents the initial guess for the model's weight.\n",
    "W = tf.Variable(np.random.normal([1]))\n",
    "\n",
    "# Initialize the bias (b) as a TensorFlow variable with a value of zero.\n",
    "# This represents the initial guess for the model's bias.\n",
    "b = tf.Variable(np.zeros([1]))\n",
    "\n",
    "# The setup is now ready for building a simple linear regression model in TensorFlow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5dd320b-3f18-4299-862c-3ed9b205aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the Mean Squared Error (MSE) loss\n",
    "def mse_loss():\n",
    "    # Calculate the predicted values (y_pred) using the current weight (W) and bias (b)\n",
    "    # This implements the linear regression equation: y_pred = W * x + b\n",
    "    y_pred = W * x + b\n",
    "    \n",
    "    # Compute the MSE loss by taking the mean of the squared differences between predictions and actual values\n",
    "    loss = tf.reduce_mean(tf.square(y_pred - y))\n",
    "    \n",
    "    # Return the computed loss value\n",
    "    return loss\n",
    "\n",
    "# Initialize the Adam optimizer for model training\n",
    "# The Adam optimizer is an adaptive learning rate optimization algorithm that is widely used for training neural networks\n",
    "optimizer = tf.keras.optimizers.Adam()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a43e1c6-2b63-4d6a-b0ce-78a306d85487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: W=[0.34764054], b=[0.00099998], Loss=0.017731882898857645\n",
      "Step 500: W=[0.25806379], b=[0.16660731], Loss=0.00029762898742903847\n",
      "Step 1000: W=[0.20320302], b=[0.19815876], Loss=9.105851540884782e-07\n",
      "Step 1500: W=[0.20003671], b=[0.1999789], Loss=1.2044699019200792e-10\n",
      "Step 2000: W=[0.20000006], b=[0.19999997], Loss=3.9607877256664005e-16\n",
      "Step 2500: W=[0.2], b=[0.2], Loss=8.596208350915329e-17\n",
      "Step 3000: W=[0.2], b=[0.2], Loss=8.596207991760071e-17\n",
      "Step 3500: W=[0.2], b=[0.2], Loss=8.596207993105941e-17\n",
      "Step 4000: W=[0.2], b=[0.2], Loss=8.596207995182022e-17\n",
      "Step 4500: W=[0.2], b=[0.2], Loss=8.596207997681379e-17\n"
     ]
    }
   ],
   "source": [
    "# Training loop for 5000 steps to optimize weights and bias\n",
    "for step in range(5000):\n",
    "    # Use GradientTape to record operations for automatic differentiation\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Calculate the current loss using the mse_loss function\n",
    "        current_loss = mse_loss()\n",
    "\n",
    "    # Compute gradients of the loss with respect to the variables W and b\n",
    "    gradients = tape.gradient(current_loss, [W, b])\n",
    "\n",
    "    # Update the weights W and bias b using the optimizer\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "\n",
    "    # Print the current values of W, b, and loss every 500 steps\n",
    "    if step % 500 == 0:\n",
    "        print(f\"Step {step}: W={W.numpy()}, b={b.numpy()}, Loss={current_loss.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16e01f8f-0719-4496-bf32-f503f18e7dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (68.2.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aec9854-29de-4b23-862e-047971a4e101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition of tensors: tensor([[3, 4],\n",
      "        [5, 6]])\n",
      "Multiplication of Tensors:  tensor([[2, 4],\n",
      "        [6, 8]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data1 = [\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "]\n",
    "\n",
    "data2 = [\n",
    "    [2, 2],\n",
    "    [2, 2]\n",
    "]\n",
    "\n",
    "x_data1 = torch.tensor(data1)\n",
    "x_data2 = torch.tensor(data2)\n",
    "\n",
    "\n",
    "addition = x_data1 + x_data2\n",
    "\n",
    "multiply = x_data1 * x_data2\n",
    "\n",
    "\n",
    "print(\"Addition of tensors:\", addition)\n",
    "print(\"Multiplication of Tensors: \", multiply)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edef068-8a4f-436b-b91e-c3a717e932d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
